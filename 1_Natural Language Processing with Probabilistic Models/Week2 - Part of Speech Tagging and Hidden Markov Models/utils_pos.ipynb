{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import string \n",
    "# Punctuation characters\n",
    "punct = set(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Morphology rules used to assign unknown word tokens\n",
    "noun_suffix = [\"action\", \"age\", \"ance\", \"cy\", \"dom\", \"ee\", \"ence\", \"er\", \"hood\", \"ion\", \"ism\", \"ist\", \"ity\", \"ling\", \"ment\", \"ness\", \"or\", \"ry\", \"scape\", \"ship\", \"ty\"]\n",
    "verb_suffix = [\"ate\", \"ify\", \"ise\", \"ize\"]\n",
    "adj_suffix = [\"able\", \"ese\", \"ful\", \"i\", \"ian\", \"ible\", \"ic\", \"ish\", \"ive\", \"less\", \"ly\", \"ous\"]\n",
    "adv_suffix = [\"ward\", \"wards\", \"wise\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additive smoothing parameter\n",
    "alpha = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_probs(states):\n",
    "    ''' \n",
    "    Input: \n",
    "        states: a set of possible parts of speech tags\n",
    "    Output: \n",
    "        trans_probs: a dictionary where the keys are states the values are dictionaries where the keys are states and the \n",
    "        values are 0.\n",
    "        \n",
    "    This dictionary will be later populated\n",
    "    '''\n",
    "    transition_probability = {}    # A dictionay of POS, \n",
    "    for state in states:\n",
    "        transition_probability[state] = 0\n",
    "    trans_pos = {}\n",
    "    for state in states:\n",
    "        trans_pos[state] = transition_probability\n",
    "        \n",
    "    return trans_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_states(tagged_corpus):\n",
    "    '''\n",
    "    Input:\n",
    "        tagged_corpus: a list of sentences \n",
    "    Output:\n",
    "        states: the states in a tuple\n",
    "        observations: the observations in a tuple\n",
    "    '''\n",
    "    states = set()\n",
    "    observations = set()\n",
    "    for sent in tagged_corpus: \n",
    "        for tup in sent: \n",
    "            word, label = tup \n",
    "            states.add(label)\n",
    "            observations.add(word)\n",
    "    observations.add('<s>')\n",
    "    states.add('<s>')\n",
    "    return tuple(states), tuple(observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_probabilities(states, observations):\n",
    "    ''' \n",
    "    Input: \n",
    "        states: a tuple of POS tags\n",
    "        observations: a tuple of possible words \n",
    "    Output: \n",
    "        trans_pos: a dictionary where the keys are the POS and the values are dictionaries where the keys are POS and the values are transitions.\n",
    "        emission_probabilities: a dictionary where the keys are the \n",
    "    ''' \n",
    "    all_words = {}\n",
    "    for observation in observations:\n",
    "        all_words[observation] = 0\n",
    "\n",
    "    # these are the two dictionaries we will fill.\n",
    "    transition_probability = {}    # A dictionay of POS, \n",
    "    emission_probabilities = {}\n",
    "\n",
    "    # these are the \n",
    "    for state in states:\n",
    "        transition_probability[state] = 0\n",
    "        #initializing \n",
    "        emission_probabilities[state] = all_words\n",
    "    trans_pos = {}\n",
    "    for state in states:\n",
    "        trans_pos[state] = transition_probability\n",
    "        \n",
    "    return trans_pos, emission_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: get_transitions\n",
    "def get_transitions(tagged_sents, states, transition_probability, emission_probability):\n",
    "    '''\n",
    "    Input: \n",
    "        train: a list of tuples where each tuple is of this form (word, label)\n",
    "    Output: \n",
    "        transition_probability: a dictionary of dictionaries (maps each word to other transitions)\n",
    "                                maybe a table.\n",
    "    '''\n",
    "    # transition_probability = {}    # A dictionay of POS, \n",
    "    # POS dictionary has the same keys and all the values are 0 at first\n",
    "    \n",
    "    ### START CODE HERE ### \n",
    "    total_count = 0\n",
    "    # Fill in the dictionary with all the number of times it appears in the \n",
    "    \n",
    "    for sent in tagged_sents:\n",
    "        prev_state = '<s>'\n",
    "        for word in sent:\n",
    "            word, label = word\n",
    "            cur_dict = transition_probability[prev_state]\n",
    "            cur_dict[label] += 1   \n",
    "            total_count += 1\n",
    "            transition_probability[prev_state] = cur_dict\n",
    "            prev_state = label\n",
    "            # Now computing the emission\n",
    "            emission_probability[label][word] +=1 \n",
    "    # Convert it into a probability\n",
    "    for state, dictionary in transition_probability.items():\n",
    "        total_words = sum(transition_probability[state].values())\n",
    "        for n_state in dictionary:\n",
    "            transition_probability[state][n_state] = transition_probability[state][n_state]/total_words\n",
    "            \n",
    "    for state, dictionary in emission_probability.items():\n",
    "        total_words = sum(emission_probability[state].values())\n",
    "        for word in dictionary:\n",
    "            emission_probability[state][word] = emission_probability[state][word]/total_words\n",
    "            \n",
    "    ### END CODE HERE ### \n",
    "    \n",
    "    return transition_probability, emission_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def assign_unk(tok):\n",
    "    \"\"\"\n",
    "    Assign unknown word tokens\n",
    "    \"\"\"\n",
    "    # Digits\n",
    "    if any(char.isdigit() for char in tok):\n",
    "        return \"--unk_digit--\"\n",
    "\n",
    "    # Punctuation\n",
    "    elif any(char in punct for char in tok):\n",
    "        return \"--unk_punct--\"\n",
    "\n",
    "    # Upper-case\n",
    "    elif any(char.isupper() for char in tok):\n",
    "        return \"--unk_upper--\"\n",
    "\n",
    "    # Nouns\n",
    "    elif any(tok.endswith(suffix) for suffix in noun_suffix):\n",
    "        return \"--unk_noun--\"\n",
    "\n",
    "    # Verbs\n",
    "    elif any(tok.endswith(suffix) for suffix in verb_suffix):\n",
    "        return \"--unk_verb--\"\n",
    "\n",
    "    # Adjectives\n",
    "    elif any(tok.endswith(suffix) for suffix in adj_suffix):\n",
    "        return \"--unk_adj--\"\n",
    "\n",
    "    # Adverbs\n",
    "    elif any(tok.endswith(suffix) for suffix in adv_suffix):\n",
    "        return \"--unk_adv--\"\n",
    "\n",
    "    return \"--unk--\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_word_tag(line, vocab): \n",
    "    if not line.split():\n",
    "        word = \"--n--\"\n",
    "        tag = \"--s--\"\n",
    "        return word, tag\n",
    "    else:\n",
    "        word, tag = line.split()\n",
    "        if word not in vocab: \n",
    "            # Handle unknown words\n",
    "            word = assign_unk(word)\n",
    "        return word, tag\n",
    "    return None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def preprocess(vocab, data_fp):\n",
    "    \"\"\"\n",
    "    Preprocess data\n",
    "    \"\"\"\n",
    "    orig = []\n",
    "    prep = []\n",
    "\n",
    "    # Read data\n",
    "    with open(data_fp, \"r\") as data_file:\n",
    "\n",
    "        for cnt, word in enumerate(data_file):\n",
    "\n",
    "            # End of sentence\n",
    "            if not word.split():\n",
    "                orig.append(word.strip())\n",
    "                word = \"--n--\"\n",
    "                prep.append(word)\n",
    "                continue\n",
    "\n",
    "            # Handle unknown words\n",
    "            elif word.strip() not in vocab:\n",
    "                orig.append(word.strip())\n",
    "                word = assign_unk(word)\n",
    "                prep.append(word)\n",
    "                continue\n",
    "\n",
    "            else:\n",
    "                orig.append(word.strip())\n",
    "                prep.append(word.strip())\n",
    "\n",
    "    assert(len(orig) == len(open(data_fp, \"r\").readlines()))\n",
    "    assert(len(prep) == len(open(data_fp, \"r\").readlines()))\n",
    "\n",
    "    return orig, prep\n",
    "# TO be deleted later \n",
    "def get_frequency(tagged_corpus):\n",
    "    '''\n",
    "    Input: \n",
    "        tagged_corpus: a list of tuples where the first element of each tuple is the word \n",
    "                       and the second is the POS.\n",
    "    Ouput: \n",
    "        freqs: a dictionary where the keys are words and the values are a list of possible tags.\n",
    "    '''\n",
    "    freqs = {} # dictionary to be returned\n",
    "    curr_words = set()\n",
    "    ### START CODE HERE ###\n",
    "    for tup in tagged_corpus:\n",
    "        word, label = tup\n",
    "        if word not in curr_words:\n",
    "            new_dict = {}\n",
    "            new_dict[label] = 1\n",
    "            freqs[word] = new_dict\n",
    "        else:\n",
    "            cur_dict = freqs[word]\n",
    "            if label in set(cur_dict.keys()):\n",
    "                cur_dict[label] += 1\n",
    "            else:\n",
    "                cur_dict[label] = 1\n",
    "            freqs[word] = cur_dict\n",
    "        curr_words.add(word)\n",
    "    ### END CODE HERE ###\n",
    "    return freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_pos(prep, y, tagged_counts):\n",
    "    '''\n",
    "    Input: \n",
    "        data: a list of tuples where each tuple consists of (word, POS)\n",
    "        freqs: a dictionary where the keys are words and the values are a list of possible tags.\n",
    "    Output: \n",
    "        accuracy: Number of times you classified a word correctly\n",
    "    '''\n",
    "    num_correct = 0\n",
    "    total = len(test_x)\n",
    "    all_words = set(freqs.keys())\n",
    "    for x, y in zip(test_x, test_y): \n",
    "        _, true_label = y \n",
    "        if x in all_words:\n",
    "            cur_dict = freqs[x]\n",
    "            pos_final = ''\n",
    "            freq_final = 0\n",
    "            for pos, freq in cur_dict.items():\n",
    "                if freq > freq_final:\n",
    "                    freq_final = freq\n",
    "                    pos_final = pos\n",
    "            if pos_final == true_label:\n",
    "                num_correct +=1 \n",
    "    return num_correct/total\n",
    "#https://github.com/melanietosik/viterbi-pos-tagger/blob/master/scripts/viterbi.py"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "notebook_metadata_filter": "-all",
   "text_representation": {
    "extension": ".py",
    "format_name": "light"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
